## python으로 크롤링

### 1. 주로 사용하는 라이브러리

- Requests : 파이썬에서 동작하는 작고 빠른 브라우저
  - 웹서버로부터 초기 HTML만 받을 뿐, 추가 CSS/JavsScript처리 없다.
  - 거의 모든 플랫폼에서 구동가능
- Selenium : 브라우저가 아니고 브라우저를 원격 컨트롤하는 테스팅 라이브러리
  - Chrome, Firefox, IE, PhantomJS등
  - 기본 브라우저를 사용하므로, 추가 CSS/JavaScript처리 지원 가능
  - 리소스를 많이 먹는다. 사이트에 따라 죽기도 한다.
- BeautifulSoup4: HTML 파서
  - 지정 HTML로부터 원하는 위치/형식의 문자열을 획득
  - 주로 Requests에 의해 많이 사용되지만, Selenium에서도 사용할 수 있다.

### 2. Selenium이 좋은 경우

- 고민하기 싫다.
- 내가 요청할 페이지가 몇 개 안된다.
- GUI가 있는 컴퓨터에서 수행한다.
- 컴퓨터 사양이 넉넉하다.
- 웹페이지가 JavaScript로 동작한다.
- => 위의 경우 중 하나라도 포함된다면 Selenium이 좋다.

### 3. 내가 원하는 컨텐츠가 별도 Ajax요청을 통해 받아오진 않는지?

- 이는 브라우저 개발자 도구의 Network탭을 통해 확인 가능하다.
- 받아오고 있다면 Requests로!

### 4. 원하는 컨텐츠가 별도 자바스크립트 로직을 통해 그려지는가?

- 자바스크립트 로직을 통해 그려진다면 로직으로 파이썬 로직으로 변환 가능한지 체크!
  - 변환 가능 => 파이썬 로직으로 변경해서 처리
  - 변환 불가 => Selenium 사용
- 모르겠거나 그렇지 않으면 Selenium사용

### 5. 페이지 소스 메뉴로 봤을 때, 내가 원하는 컨텐츠가 있는가?

- 있으면 Requests로

### 6. ActiveX사이트

- Selenium으로 IE를 통해 자동화 시도
- 하지만 매번 ActiveX설치 이벤트 처리 까다로우므로 가급적 피해가기

### 7. Requests 크롤링 tip!

- 요청 시에 종종 추가 헤더  설정 필요할 수 있다. 헤더를 설정하지 않으면 응답을 안해주는 서비스가 있다.
  - Referer
  - User-Agent
  - Accept-Language
- 모바일 페이지가 있다면 모바일 페이지로 크롤링. HTML마크업보다 심플하다.
- 크롤링시 파이썬파일로 인식할 때가 있는데 이를 크롬이나 다른 브라우저로 인식하기 위해서 [참고사이트,user agent string](http://www.useragentstring.com/)를 참고한다.
- ![스크린샷 2020-03-17 오전 11.46.20](크롤링.assets/스크린샷 2020-03-17 오전 11.46.20.png)
- 



###  총체적 정리

1. 단순 HTML 크롤링
   - Requests
2. Ajax 렌더링 크롤링
   - Requests로 해볼 수 있으면 하고 어려우면 Selenium
3. AngularJS, Vue.js, React.JS 류의 자바스크립트 렌더링 크롤링
   - Selenium으로 
   - 분석하기에 따라 requests로 가능
4. 이도저도 아니며 생각하기 힘들면 Selenium

### 사이트별 라이브 데모

- 네이버 실시간 검색어 : 정적 HTML
- 멜론 검색: Ajax 렌더링
- .....추가



## 유튜브 크롤링

1. 자막 크롤링

## 